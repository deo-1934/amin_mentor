#FEYZ
#DEO
# -*- coding: utf-8 -*-
import os
import json
import time
from typing import Dict, Any

import streamlit as st

try:
    from app.generator import generate_answer, load_settings
except Exception:
    from generator import generate_answer, load_settings

st.set_page_config(page_title="Amin Mentor", page_icon="ğŸ¤", layout="wide")

st.markdown("### Ù…Ù†ØªÙˆØ± Ø´Ø®ØµÛŒ Ø§Ù…ÛŒÙ†\nÙ¾Ø§Ø³Ø® Ø³Ù‡â€ŒØ¨Ø®Ø´ÛŒ: Ù…Ù‚Ø¯Ù…Ù‡ØŒ Ù‡Ø³ØªÙ‡ØŒ Ø¬Ù…Ø¹â€ŒØ¨Ù†Ø¯ÛŒ.")

col_left, col_right = st.columns([2, 1], gap="large")
settings = load_settings()

with col_left:
    st.subheader("Ø³Ø¤Ø§Ù„ Ø´Ù…Ø§")
    user_query = st.text_area(
        "Ù…ØªÙ† Ø³Ø¤Ø§Ù„:",
        placeholder="Ù…Ø«Ù„Ø§Ù‹: Ú†Ø·ÙˆØ± Ø¨Ø§ Ú©Ù…ØªØ±ÛŒÙ† Ù‡Ø²ÛŒÙ†Ù‡ API Ø±Ùˆ ÙˆØµÙ„ Ú©Ù†Ù…ØŸ",
        height=160
    )

    with st.expander("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡", expanded=False):
        provider_options = ["openai", "huggingface", "offline"]
        try:
            default_idx = provider_options.index(settings.get("MODEL_PROVIDER", "openai"))
        except ValueError:
            default_idx = 0
        model_provider = st.selectbox("Model Provider:", options=provider_options, index=default_idx)

        # OpenAI fields
        openai_model = st.text_input(
            "OPENAI_MODEL",
            value=settings.get("OPENAI_MODEL", "gpt-4o-mini"),
            placeholder="gpt-4o-mini / gpt-4.1-mini / ...",
            help="Ø§Ú¯Ø± Provider=openai Ø¨Ø§Ø´Ø¯"
        )
        openai_api_key = st.text_input(
            "OPENAI_API_KEY",
            value=settings.get("OPENAI_API_KEY", ""),
            type="password",
            help="Ø¯Ø± Secrets Ø³Øª Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯ Ø¨Ù‡ØªØ± Ø§Ø³Øª"
        )

        # HF fields
        model_endpoint = st.text_input(
            "MODEL_ENDPOINT (HuggingFace)",
            value=settings.get("MODEL_ENDPOINT", ""),
            placeholder="https://api-inference.huggingface.co/models/gpt2",
            help="Ø§Ú¯Ø± Provider=huggingface Ø¨Ø§Ø´Ø¯"
        )
        hf_token = st.text_input(
            "HF_TOKEN",
            value=settings.get("HF_TOKEN", ""),
            type="password"
        )

        temperature = st.slider("Temperature", 0.0, 1.5, value=0.2, step=0.05)
        max_new_tokens = st.slider("Max new tokens", 16, 1024, value=256, step=16)
        top_k = st.slider("Top-K Retrieval", 1, 10, value=5, step=1)
        show_raw = st.checkbox("Ù†Ù…Ø§ÛŒØ´ Ø®Ø±ÙˆØ¬ÛŒ Ø®Ø§Ù… (Debug)", value=False)

    ask = st.button("ğŸš€ Ø¨Ù¾Ø±Ø³", use_container_width=True)

#DEO
with col_right:
    st.subheader("ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒØ³ØªÙ…")
    st.code(json.dumps({
        "provider": settings.get("MODEL_PROVIDER"),
        "has_openai_key": bool(settings.get("OPENAI_API_KEY")),
        "has_hf_token": bool(settings.get("HF_TOKEN")),
        "cache_path": settings.get("CACHE_PATH"),
    }, ensure_ascii=False, indent=2))
    st.info("Ø§Ú¯Ø± Ø§Ø² OpenAI Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒØŒ OPENAI_API_KEY Ø±Ø§ Ø¯Ø± Secrets Ø¨Ú¯Ø°Ø§Ø±.", icon="â„¹ï¸")

if ask:
    if not user_query.strip():
        st.warning("Ø§ÙˆÙ„ Ø³Ø¤Ø§Ù„ Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³.", icon="âš ï¸")
    else:
        cfg: Dict[str, Any] = dict(
            model_provider=model_provider,
            # OpenAI
            openai_model=openai_model,
            openai_api_key=openai_api_key,
            # HF
            model_endpoint=model_endpoint,
            hf_token=hf_token,
            # common
            temperature=temperature,
            max_new_tokens=max_new_tokens,
            top_k=top_k,
        )
        t0 = time.time()
        with st.spinner("Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®..."):
            try:
                result = generate_answer(user_query, **cfg)
            except Exception as e:
                st.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®: {e}")
                result = None
        dt = time.time() - t0

        if result is not None:
            st.success(f"âœ… Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯ (Ø²Ù…Ø§Ù†: {dt:.2f}s)")
            st.markdown("#### Ù…Ù‚Ø¯Ù…Ù‡"); st.write(result.get("intro", ""))
            st.markdown("#### Ù‡Ø³ØªÙ‡Ù” Ù¾Ø§Ø³Ø®"); st.write(result.get("core", ""))
            st.markdown("#### Ø¬Ù…Ø¹â€ŒØ¨Ù†Ø¯ÛŒ"); st.write(result.get("outro", ""))

            if show_raw:
                st.markdown("#### RAW")
                st.code(json.dumps(result, ensure_ascii=False, indent=2))

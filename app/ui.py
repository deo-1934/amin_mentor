# app/ui.py
# Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ Streamlit Ø¨Ø±Ø§ÛŒ Ù…Ù†ØªÙˆØ± Ø´Ø®ØµÛŒ Ø¨Ø§ Ø­Ø§ÙØ¸Ù‡ Ù…Ú©Ø§Ù„Ù…Ù‡ Ùˆ Ù„Ø­Ù† Ù‚Ø§Ø¨Ù„ Ø§Ù†ØªØ®Ø§Ø¨

import os
import textwrap
from pathlib import Path
import sys

import streamlit as st
from dotenv import load_dotenv

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ø³ÛŒØ± Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ù…Ø§Ú˜ÙˆÙ„â€ŒÙ‡Ø§
BASE_DIR = Path(__file__).resolve().parents[1]
sys.path.append(str(BASE_DIR / "app"))

# Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ø§Ø¬Ø²Ø§ÛŒ Ø¯Ø§Ø®Ù„ÛŒ
from retriever import Retriever
from persona import SYSTEM_PERSONA, STYLE_PRESETS
from memory import ChatMemory

# Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ ØµÙØ­Ù‡
load_dotenv()
st.set_page_config(page_title="Ù…Ù†ØªÙˆØ± Ø´Ø®ØµÛŒ", page_icon="ğŸ¤–", layout="wide")
st.title("ğŸ¤– Ù…Ù†ØªÙˆØ± Ø´Ø®ØµÛŒ Ø¨Ø§ Ø­Ø§ÙØ¸Ù‡ Ùˆ Ø³Ø¨Ú© Ù¾Ø§Ø³Ø® Ø³ÙØ§Ø±Ø´ÛŒ")

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª API
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()
MODEL_NAME = os.getenv("MODEL_NAME", "gpt-4o-mini")

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³Ø§ÛŒØ¯Ø¨Ø§Ø±
with st.sidebar:
    st.subheader("ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾Ø§Ø³Ø®")
    if OPENAI_API_KEY:
        st.success("Ø­Ø§Ù„Øª Ø¢Ù†Ù„Ø§ÛŒÙ† (Ø¨Ø§ Ù…Ø¯Ù„ Ø²Ø¨Ø§Ù†ÛŒ)")
    else:
        st.warning("Ø­Ø§Ù„Øª Ø¢ÙÙ„Ø§ÛŒÙ† (Ø¨Ø¯ÙˆÙ† Ú©Ù„ÛŒØ¯ OpenAI)")

    top_k = st.slider("ØªØ¹Ø¯Ø§Ø¯ Ù†ØªØ§ÛŒØ¬ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒâ€ŒØ´Ø¯Ù‡", 3, 15, 5)
    style_name = st.selectbox("Ø³Ø¨Ú© Ù¾Ø§Ø³Ø®", list(STYLE_PRESETS.keys()), index=0)
    st.caption("Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø¨Ø§ÛŒØ¯ Ø¯Ø± Ù¾ÙˆØ´Ù‡ faiss_index Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯ (index.faiss Ùˆ meta.json).")

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø§ÛŒÙ†Ø¯Ú©Ø³
try:
    retriever = Retriever()
except Exception as e:
    st.error(
        f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø§ÛŒÙ†Ø¯Ú©Ø³: {e}\n"
        "Ø§Ø¨ØªØ¯Ø§ Ø¯Ø³ØªÙˆØ± Ø²ÛŒØ± Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù†:\n`python ingest/build_faiss.py`"
    )
    st.stop()

# Ø­Ø§ÙØ¸Ù‡ Ù…Ú©Ø§Ù„Ù…Ù‡ Ø¯Ø± Session State
if "memory" not in st.session_state:
    st.session_state["memory"] = ChatMemory()
memory: ChatMemory = st.session_state["memory"]

# ÙˆØ±ÙˆØ¯ÛŒ Ú©Ø§Ø±Ø¨Ø±
query = st.text_input("Ø³Ø¤Ø§Ù„Øª ÛŒØ§ Ù…ÙˆØ¶ÙˆØ¹ Ù…ÙˆØ±Ø¯Ù†Ø¸Ø± Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³:", placeholder="Ù…Ø«Ù„Ø§Ù‹: Ù‡Ø¯Ù Ù…Ø°Ø§Ú©Ø±Ù‡ Ø¨Ø±Ø¯-Ø¨Ø±Ø¯ Ú†ÛŒØ³ØªØŸ")
ask = st.button("Ù¾Ø±Ø³ÛŒØ¯Ù†")

# ØªØ§Ø¨Ø¹ ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø§ Ù…Ø¯Ù„ Ø²Ø¨Ø§Ù†ÛŒ
def llm_answer(context: str, q: str, style_desc: str) -> str:
    if not OPENAI_API_KEY:
        return None  # Ø­Ø§Ù„Øª Ø¢ÙÙ„Ø§ÛŒÙ†
    try:
        from openai import OpenAI
        client = OpenAI(api_key=OPENAI_API_KEY)

        history_text = memory.as_text()

        prompt = f"""
{SYSTEM_PERSONA}

Ø³Ø¨Ú© Ù¾Ø§Ø³Ø®: {style_desc}

Ú¯ÙØªÚ¯ÙˆÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ±:
{history_text if history_text else "â€”"}

Ù¾Ø±Ø³Ø´ Ø¬Ø¯ÛŒØ¯: {q}

Ù…ØªÙˆÙ† Ù…Ø±ØªØ¨Ø· (Context):
{context}

Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„:
- Ø§Ú¯Ø± Ù¾Ø§Ø³Ø® Ø¯Ø± Ù…ØªÙˆÙ† Ù†Ø¨ÙˆØ¯ØŒ Ø¨Ú¯Ùˆ Ù…Ø·Ù…Ø¦Ù† Ù†ÛŒØ³ØªÙ… Ùˆ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…Ø³ÛŒØ± Ø¬Ø³Øªâ€ŒÙˆØ¬Ùˆ Ø¨Ø¯Ù‡.
- Ø¯Ø± Ù¾Ø§ÛŒØ§Ù†ØŒ ÛŒÚ© Ú¯Ø§Ù… Ø¹Ù…Ù„ÛŒ Ø³Ø±ÛŒØ¹ (Action) Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ú©Ù†.
"""

        r = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
        )
        return r.choices[0].message.content

    except Exception as e:
        st.info(f"âš ï¸ Ù…Ø´Ú©Ù„ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ù…Ø¯Ù„ Ø²Ø¨Ø§Ù†ÛŒ: {e}")
        return None

# Ø§Ø¬Ø±Ø§
if ask and query:
    memory.add("user", query)

    with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ø¬Ø³Øªâ€ŒÙˆØ¬ÙˆÛŒ Ø§Ø³Ù†Ø§Ø¯ Ù…Ø±ØªØ¨Ø·..."):
        hits = retriever.search(query, k=top_k)

    if not hits:
        st.warning("Ù‡ÛŒÚ† Ø³Ù†Ø¯ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. Ù…Ø·Ù…Ø¦Ù† Ø´Ùˆ Ù¾ÙˆØ´Ù‡ data/ Ø®Ø§Ù„ÛŒ Ù†Ø¨Ø§Ø´Ø¯ Ùˆ Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯.")
    else:
        col_ans, col_refs = st.columns([2, 1])

        with col_refs:
            st.subheader("ğŸ“š Ø§Ø³Ù†Ø§Ø¯ Ù…Ø±ØªØ¨Ø·")
            for i, h in enumerate(hits, 1):
                with st.expander(f"{i}. {h['source']} (score={h['score']:.3f})", expanded=(i == 1)):
                    st.write(h["text"])

        with col_ans:
            st.subheader("ğŸ’¬ Ù¾Ø§Ø³Ø® Ù…Ù†ØªÙˆØ±")
            context = "\n\n".join([f"[Ù…Ù†Ø¨Ø¹: {h['source']}]\n{h['text']}" for h in hits])
            style_desc = STYLE_PRESETS.get(style_name, "")
            answer = llm_answer(context, query, style_desc)

            if not answer:
                # Ø­Ø§Ù„Øª Ø¢ÙÙ„Ø§ÛŒÙ†: Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø§Ø¯Ù‡ Ø§Ø² Ù†ØªØ§ÛŒØ¬
                bullets = []
                for h in hits:
                    snippet = h["text"].replace("\n", " ")
                    snippet = textwrap.shorten(snippet, width=220, placeholder="â€¦")
                    bullets.append(f"â€¢ {snippet}")
                answer = "\n".join(bullets)

            st.write(answer)
            memory.add("assistant", answer)

st.caption("Ø³Ø§Ø®ØªÙ‡â€ŒØ´Ø¯Ù‡ Ø¨Ø§ â¤ï¸ Ø¨Ø±Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡ Ù…Ù†ØªÙˆØ± Ø´Ø®ØµÛŒ | Ø­Ø§ÙØ¸Ù‡ ÙØ¹Ø§Ù„ + Ø³Ø¨Ú© Ù¾Ø§Ø³Ø® Ù‚Ø§Ø¨Ù„ ØªÙ†Ø¸ÛŒÙ…")

#FEYZ
#DEO
import os
import json
import hashlib
import requests
from datetime import datetime

# --------------------------------------------
# ğŸ“ Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ú©Ø´ Ù…Ø­Ù„ÛŒ (Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ)
# --------------------------------------------
CACHE_PATH = os.path.join("data", "cache.json")
os.makedirs("data", exist_ok=True)
if not os.path.exists(CACHE_PATH):
    with open(CACHE_PATH, "w", encoding="utf-8") as f:
        json.dump({}, f, ensure_ascii=False, indent=2)


# --------------------------------------------
# ğŸ§  Rule-Based Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø¯Ù‡ Ùˆ ØªÚ©Ø±Ø§Ø±ÛŒ
# --------------------------------------------
def rule_based_answer(question: str):
    q = question.strip().lower()
    rules = {
        "Ø³Ù„Ø§Ù…": "Ø³Ù„Ø§Ù… Ø®ÙˆØ´ Ø§ÙˆÙ…Ø¯ÛŒ ğŸŒ¸",
        "Ø®Ø¯Ø§Ø­Ø§ÙØ¸": "ÙØ¹Ù„Ø§Ù‹ØŒ Ù…Ø±Ø§Ù‚Ø¨ Ø®ÙˆØ¯Øª Ø¨Ø§Ø´ ğŸ˜Š",
        "Ú©ÛŒ Ù‡Ø³ØªÛŒ": "Ù…Ù† Ù…Ù†ØªÙˆØ± Ø´Ø®ØµÛŒ Ø§Ù…ÛŒÙ†Ù… ğŸ§ ØŒ Ù‡Ù…ÛŒØ´Ù‡ Ú©Ù†Ø§Ø±ØªÙ….",
        "Ø§Ø³Ù…": "Ù…Ù† Ù…Ù†ØªÙˆØ± Ø´Ø®ØµÛŒ Ø§Ù…ÛŒÙ†Ù… ğŸŒ±",
        "Ø³Ø§Ø¹Øª": f"Ø§Ù„Ø§Ù† Ø³Ø§Ø¹Øª {datetime.now().strftime('%H:%M')} Ù‡Ø³Øª â°",
        "ØªØ§Ø±ÛŒØ®": f"Ø§Ù…Ø±ÙˆØ² {datetime.now().strftime('%Y-%m-%d')} Ù‡Ø³Øª ğŸ“…",
    }
    for k, v in rules.items():
        if k in q:
            return v
    return None


# --------------------------------------------
# ğŸ’¾ Ø³ÛŒØ³ØªÙ… Ú©Ø´ (Cache)
# --------------------------------------------
def load_cache():
    with open(CACHE_PATH, "r", encoding="utf-8") as f:
        return json.load(f)

def save_cache(cache):
    with open(CACHE_PATH, "w", encoding="utf-8") as f:
        json.dump(cache, f, ensure_ascii=False, indent=2)

def get_cached_answer(question: str):
    cache = load_cache()
    key = hashlib.md5(question.encode()).hexdigest()
    return cache.get(key)

def set_cached_answer(question: str, answer: str):
    cache = load_cache()
    key = hashlib.md5(question.encode()).hexdigest()
    cache[key] = answer
    save_cache(cache)


# --------------------------------------------
# ğŸ¤– ØªÙ…Ø§Ø³ Ø¨Ø§ API ÙÙ‚Ø· Ø¯Ø±ØµÙˆØ±Øª Ù†ÛŒØ§Ø²
# --------------------------------------------
def call_openai_api(prompt: str):
    headers = {
        "Authorization": f"Bearer {os.getenv('OPENAI_API_KEY') or os.getenv('HF_TOKEN')}",
        "Content-Type": "application/json",
    }

    payload = {
        "model": "gpt-4o-mini",
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": 400,
        "temperature": 0.7,
    }

    response = requests.post(
        "https://api.openai.com/v1/chat/completions", headers=headers, json=payload
    )
    if response.status_code == 200:
        data = response.json()
        return data["choices"][0]["message"]["content"]
    else:
        return f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ù…Ø¯Ù„: {response.text}"


# --------------------------------------------
# ğŸ”· ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® (Hybrid)
# --------------------------------------------
def generate_answer(user_question: str, context: list):
    """
    Ù…Ù†Ø·Ù‚ Ø³Ù‡â€ŒÙ…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ:
      1. rule-based Ù¾Ø§Ø³Ø® Ø³Ø§Ø¯Ù‡
      2. cache Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª ØªÚ©Ø±Ø§Ø±ÛŒ
      3. ØªÙ…Ø§Ø³ Ø¨Ø§ API Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²
    """

    # Ù…Ø±Ø­Ù„Ù‡ 1: Rule-based
    rb_answer = rule_based_answer(user_question)
    if rb_answer:
        return rb_answer

    # Ù…Ø±Ø­Ù„Ù‡ 2: Cache
    cached = get_cached_answer(user_question)
    if cached:
        return cached

    # Ù…Ø±Ø­Ù„Ù‡ 3: Ø³Ø§Ø®Øª prompt Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„
    context_text = "\n".join(context[-3:]) if context else ""
    prompt = f"""
    [Ø³Ø§Ø¨Ù‚Ù‡ Ú¯ÙØªÚ¯Ùˆ ØªØ§ Ø§ÛŒÙ†Ø¬Ø§]
    {context_text}

    [Ù¾Ø±Ø³Ø´ Ú©Ø§Ø±Ø¨Ø±]
    {user_question}

    Ù„Ø·ÙØ§Ù‹ Ù…Ø«Ù„ ÛŒÚ© Ù…Ù†ØªÙˆØ± Ø¨Ø§Ù‡ÙˆØ´ Ùˆ Ù…Ù‡Ø±Ø¨ÙˆÙ† Ù¾Ø§Ø³Ø® Ø¨Ø¯Ù‡ØŒ
    Ù…Ø®ØªØµØ±ØŒ ÙˆØ§Ø¶Ø­ Ùˆ Ø¨Ø§ Ù„Ø­Ù† Ø·Ø¨ÛŒØ¹ÛŒ.
    """

    answer = call_openai_api(prompt)

    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± cache
    set_cached_answer(user_question, answer)

    return answer

#FEYZ
#DEO
